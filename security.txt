Need to make sure this webscraper is:
1. respectful towards the website
  - Compliance with nfl.com/robots.txt
2. contain measures that makes it hard to ban
  - Request Throttling (implement delays between requests)
  - Proxy? (I am not planning to go against compliance so I do not think I will need this.)
  - Headless Browser (Maybe useful for search speed. Will use when project is complete.)
  - Error Handling (gracefully manage HTTP error codes or exceptions without repeatedly
                    hitting the server after an error.)

Compliance:
- According to nfl.com/robots.txt this scraper is in compliance.

########################################################
#   User-agent: *                                      #
#   Disallow: /_ctv/                                   #
#   Disallow: /_fantasy-app/                           #
#   Disallow: /_libraries/                             #
#   Disallow: /_mobile-app/                            #
#   Disallow: /_mobileview/                            #
#   Disallow: /_phs/                                   #
#   Disallow: /_sponsors/                              #
#   Disallow: /account/                                #
#   Disallow: /nfl-films-beta/                         #
#   Disallow: /search/                                 #
#   Sitemap: https://www.nfl.com/sitemap-index.xml     #
#                                                      #
#   User-agent: Mediapartners-Google                   #
#   Disallow: /stats/player-stats/*                    #
########################################################